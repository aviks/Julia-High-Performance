{
 "cells": [
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Chapter 7"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    ";nvidia-smi\n",
    "\n",
    "\n",
    "using BenchmarkTools\n",
    "using Pkg\n",
    "Pkg.add(\"CUDAnative\");\n",
    "Pkg.add(\"CuArrays\");\n",
    "Pkg.add(\"CUDAdrv\");"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## CUDAnative"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using CUDAnative\n",
    "function cudaprint(n)\n",
    "    @cuprintf(\"Thread %ld prints: %ld\\n\",\n",
    "        threadIdx().x, n)\n",
    "     return\n",
    " end\n",
    "\n",
    " @cuda threads=4 cudaprint(10)\n",
    "\n",
    " @device_code_ptx @cuda cudaprint(10)\n",
    "\n",
    " @device_code_sass @cuda cudaprint(10)\n",
    "\n",
    " @device_code_lowered @cuda cudaprint(10)\n",
    " # # CuArrays\n",
    " using CuArrays\n",
    "\n",
    " a=CuArray([1f0, 2f0, 3f0])\n",
    "\n",
    " b = a.^2 .- a.*2 .+ sqrt.(a)\n",
    "# ## Monte Carlo simulations on the GPU\n",
    "using CuArrays.CURAND\n",
    "\n",
    "function pi_gpu(n)\n",
    "   4 * sum(curand(Float64, n).^2 .+ curand(Float64, n).^2 .<= 1) / n\n",
    " end\n",
    "\n",
    " function pi_serial(n)\n",
    "   inside = 0\n",
    "   for i in 1:n\n",
    "       x, y = rand(), rand()\n",
    "       inside += (x^2 + y^2 <= 1)\n",
    "   end\n",
    "   return 4 * inside / n\n",
    "end\n",
    "\n",
    "@btime pi_serial(10_000_000)\n",
    "\n",
    "@btime pi_gpu(10_000_000)\n",
    "\n",
    "function pi_gpu32(n)\n",
    "   4 * sum(curand(Float32, n).^2 .+ curand(Float32, n).^2 .<= 1) / n\n",
    "end\n",
    "\n",
    "@btime pi_gpu32(10_000_000)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## Writing your own kernels"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function add_gpu!(y, x)\n",
    "   index = threadIdx().x\n",
    "   stride = blockDim().x\n",
    "      for i = index:stride:length(y)\n",
    "        @inbounds y[i] += x[i]\n",
    "      end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "N=1000_000\n",
    "a = cufill(1.0f0, N)\n",
    "b = cufill(2.0f0, N)\n",
    "@cuda threads=256 add_gpu!(b, a)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## Measuring GPU Performance"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "a = CuArray{Float32}(undef, 1024);\n",
    "\n",
    "@btime identity.($a);\n",
    "\n",
    "@btime CuArrays.@sync(identity.($a));\n",
    "\n",
    "CuArrays.@time pi_gpu(10_000_000)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## Performance Tips"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Scalar Iteration"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function addcol_scalar(a, b)\n",
    "   s = size(a)\n",
    "   for j = 1:s[2]\n",
    "      for i = 1:s[1]\n",
    "         @inbounds a[i,j] = b[i,j+1] + b[i,j]\n",
    "      end\n",
    "   end\n",
    " end\n",
    "\n",
    " function addcol_fast(a, b)\n",
    "   s = size(a)\n",
    "   for j = 1:s[2]\n",
    "      @inbounds a[:,j] .= b[:,j+1] + b[:,j]\n",
    "   end\n",
    "end\n",
    "\n",
    "a = ones(Float32, 10000, 99);\n",
    "b = ones(Float32, 10000, 100);\n",
    "@btime addcol_scalar($a, $b)\n",
    "\n",
    "@btime addcol_scalar($(CuArray(a)), $(CuArray(b))) samples=1;\n",
    "\n",
    "@btime addcol_fast($(CuArray(a)), $(CuArray(b)));\n",
    "\n",
    "CuArrays.allowscalar(false)\n",
    "\n",
    "addcol_scalar(CuArray(a), CuArray(b))  # Will Error!"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Combine kernels"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function addcol_faster(a, b)\n",
    "   a .= @views b[:, 2:end] .+ b[:, 1:end-1]\n",
    "end\n",
    "\n",
    "@btime addcol_faster($a, $b);\n",
    "\n",
    "@btime addcol_faster($(CuArray(a)), $(CuArray(b))) ;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Process more data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "a = ones(Float32,1000_000, 99);\n",
    "\n",
    "b = ones(Float32, 1000_000, 100);\n",
    "\n",
    "@btime addcol_faster($a, $b);\n",
    "\n",
    "@btime addcol_faster($(CuArray(a)), $(CuArray(b))) ;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## Deep learning on the GPU"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Pkg\n",
    "Pkg.add(\"Flux\")\n",
    "CuArrays.allowscalar(true)\n",
    "\n",
    "using Flux, Flux.Data.MNIST, Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated, partition\n",
    "\n",
    "imgs = MNIST.images()\n",
    "\n",
    "labels = onehotbatch(MNIST.labels(), 0:9)\n",
    "\n",
    "# Partition into batches of size 32\n",
    "train = [(cat(float.(imgs[i])..., dims = 4), labels[:,i])\n",
    " for i in partition(1:60_000, 32)]\n",
    "# Prepare test set (first 1,000 images)\n",
    "tX = cat(float.(MNIST.images(:test)[1:1000])..., dims = 4)\n",
    "tY = onehotbatch(MNIST.labels(:test)[1:1000], 0:9)\n",
    "\n",
    "\n",
    "m = Chain(\n",
    " Conv((3, 3), 1=>32, relu),\n",
    " Conv((3, 3), 32=>32, relu),\n",
    " x -> maxpool(x, (2,2)),\n",
    " Conv((3, 3), 32=>16, relu),\n",
    " x -> maxpool(x, (2,2)),\n",
    " Conv((3, 3), 16=>10, relu),\n",
    " x -> reshape(x, :, size(x, 4)),\n",
    " Dense(90, 10), softmax)\n",
    "\n",
    " loss(x, y) = crossentropy(m(x), y)\n",
    " accuracy(x, y) = mean(onecold(m(x)) .== onecold(y))\n",
    " opt = ADAM()\n",
    " @time Flux.train!(loss, Flux.params(m), train[1:10], opt)\n",
    " @show(accuracy(tX, tY))\n",
    "\n",
    "gputrain = gpu.(train[1:10])\n",
    "gpum = gpu(m)\n",
    "gputX = gpu(tX)\n",
    "gputY = gpu(tY)\n",
    "gpuloss(x, y) = crossentropy(gpum(x), y)\n",
    "gpuaccuracy(x, y) = mean(onecold(gpum(x)) .== onecold(y))\n",
    "gpuopt = ADAM()\n",
    "Flux.train!(gpuloss, Flux.params(gpum), gpu.(train[1:1]), opt)\n",
    "@time Flux.train!(gpuloss, Flux.params(gpum), gputrain, opt)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## ArrayFire"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Pkg.add(\"ArrayFire\")\n",
    "using ArrayFire\n",
    "\n",
    "a=rand(1000,1000);\n",
    "\n",
    "b=AFArray(a);\n",
    "\n",
    "c=b*b;\n",
    "\n",
    "d=Array(c);\n",
    "\n",
    "@btime $b*$b;\n",
    "\n",
    "@btime $a*$a;\n",
    "\n",
    "@btime begin; sin($b); sync($b); end;\n",
    "\n",
    "@btime sin.($a);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  },
  "kernelspec": {
   "name": "julia-1.1",
   "display_name": "Julia 1.1.0",
   "language": "julia"
  }
 },
 "nbformat": 4
}
